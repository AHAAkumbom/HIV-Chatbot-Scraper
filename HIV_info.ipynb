{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d511b41-bf31-4ee8-97e5-f57f82bb340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\haggai akumbom\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haggai akumbom\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c149289b-18f9-49c6-8baf-7953f8b36bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.27.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4994b18-ec96-4bc6-b1a8-5ccbfdb4341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35cc0dab-88c6-41cd-bde1-6de15c5b32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.pasteur.fr/fr/centre-medical/fiches-maladies/sida-vih\",\n",
    "    \"https://preventionsida.org/fr/vih/le-vih-cest-quoi/\",\n",
    "    \"https://www.hiv.gov/hiv-basics/overview/about-hiv-and-aids/what-are-hiv-and-aids\",\n",
    "    \"https://www.cdc.gov/hiv/about/index.html\",\n",
    "    \"https://info.health.nz/conditions-treatments/infectious-diseases/hiv-and-aids\",\n",
    "    \"https://www.unaids.org/en/frequently-asked-questions-about-hiv-and-aids\",\n",
    "    \"https://hivinfo.nih.gov/understanding-hiv/fact-sheets/hiv-and-aids-basics\",\n",
    "    \"https://www.cdc.gov/hiv/index.html\",\n",
    "    \"https://www.healthline.com/health/hiv-aids\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85b7c5d-40a7-4f70-999f-28a0ee378af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape all information from a webpage\n",
    "def scrape_website(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for HTTP request errors\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract all text content\n",
    "        text_content = soup.get_text(separator='\\n').strip()\n",
    "        \n",
    "        # Extract all links\n",
    "        links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "        \n",
    "        # Extract all images\n",
    "        images = [img['src'] for img in soup.find_all('img', src=True)]\n",
    "        \n",
    "        # Extract metadata (title, description, etc.)\n",
    "        title = soup.title.string if soup.title else \"No title\"\n",
    "        meta_description = soup.find('meta', attrs={'name': 'description'})\n",
    "        description = meta_description['content'] if meta_description else \"No description\"\n",
    "        \n",
    "        return {\n",
    "            'url': url,\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'text_content': text_content,\n",
    "            'links': links,\n",
    "            'images': images\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d5acaa-cd91-492a-a958-fa6a5fcbcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scraped data to IBM Watson Assistant format\n",
    "def convert_to_watson_format(scraped_data):\n",
    "    watson_data = {\n",
    "        \"intents\": [],\n",
    "        \"entities\": [],\n",
    "        \"dialog_nodes\": []\n",
    "    }\n",
    "    \n",
    "    # Add intents and dialog nodes\n",
    "    for idx, page in enumerate(scraped_data):\n",
    "        intent_name = f\"page_{idx + 1}_info\"\n",
    "        watson_data[\"intents\"].append({\n",
    "            \"intent\": intent_name,\n",
    "            \"examples\": [\n",
    "                { \"text\": f\"What is the content of {page['url']}?\" },\n",
    "                { \"text\": f\"Tell me about {page['title']}.\" },\n",
    "                { \"text\": f\"Can you summarize the information on {page['url']}?\" }\n",
    "            ]\n",
    "        })\n",
    "        watson_data[\"dialog_nodes\"].append({\n",
    "            \"dialog_node\": f\"node_{idx + 1}\",\n",
    "            \"conditions\": f\"#{intent_name}\",\n",
    "            \"output\": {\n",
    "                \"generic\": [\n",
    "                    {\n",
    "                        \"response_type\": \"text\",\n",
    "                        \"values\": [\n",
    "                            { \"text\": f\"Here is the information about {page['title']}: {page['text_content']}\" }\n",
    "                        ],\n",
    "                        \"selection_policy\": \"sequential\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add entities (e.g., images and links)\n",
    "    all_links = set(link for page in scraped_data for link in page['links'])\n",
    "    all_images = set(img for page in scraped_data for img in page['images'])\n",
    "    watson_data[\"entities\"].append({\n",
    "        \"entity\": \"link\",\n",
    "        \"values\": [{\"value\": link} for link in all_links]\n",
    "    })\n",
    "    watson_data[\"entities\"].append({\n",
    "        \"entity\": \"image\",\n",
    "        \"values\": [{\"value\": img} for img in all_images]\n",
    "    })\n",
    "    \n",
    "    return watson_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0686eafb-9f65-40fa-a11d-cd3f8f299959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://www.pasteur.fr/fr/centre-medical/fiches-maladies/sida-vih\n",
      "Scraping: https://preventionsida.org/fr/vih/le-vih-cest-quoi/\n",
      "Scraping: https://www.hiv.gov/hiv-basics/overview/about-hiv-and-aids/what-are-hiv-and-aids\n",
      "Scraping: https://www.cdc.gov/hiv/about/index.html\n",
      "Scraping: https://info.health.nz/conditions-treatments/infectious-diseases/hiv-and-aids\n",
      "Scraping: https://www.unaids.org/en/frequently-asked-questions-about-hiv-and-aids\n",
      "Scraping: https://hivinfo.nih.gov/understanding-hiv/fact-sheets/hiv-and-aids-basics\n",
      "Scraping: https://www.cdc.gov/hiv/index.html\n",
      "Scraping: https://www.healthline.com/health/hiv-aids\n"
     ]
    }
   ],
   "source": [
    "# Scrape each URL\n",
    "scraped_data = []\n",
    "for url in urls:\n",
    "    print(f\"Scraping: {url}\")\n",
    "    website_data = scrape_website(url)\n",
    "    if website_data:\n",
    "        scraped_data.append(website_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6283d63a-c0e5-4538-beab-c446abd73ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scraped data to Watson format\n",
    "watson_ready_data = convert_to_watson_format(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b631ce1-739b-4937-9ee5-23bc12f12ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete. Watson-compatible data saved to hiv-watson_data.json\n"
     ]
    }
   ],
   "source": [
    "# Save the Watson-compatible data to a JSON file\n",
    "output_file = 'hiv-watson_data.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(watson_ready_data, f, indent=4)\n",
    "\n",
    "print(f\"Scraping complete. Watson-compatible data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e23c1-d083-4d6d-95f2-8596f9780b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
